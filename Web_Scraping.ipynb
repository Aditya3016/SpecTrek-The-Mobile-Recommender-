# **Web Scraping**

import pandas as pd
import requests
from bs4 import BeautifulSoup
import re

# Lists to store scraped data
Product_Name = []
Prices = []
Description = []
Reviews = []
RAM = []
ROM = []
Battery = []
Brands = []

# Known mobile brands
known_brands = [
    "Samsung", "Redmi", "Realme", "iQOO", "Vivo", "Motorola", "Infinix", "POCO",
    "Lava", "Nokia", "OnePlus", "Nothing", "Apple", "Tecno", "Micromax", "Honor"
]

# Function to extract brand from product name
def extract_brand(name):
    for brand in known_brands:
        if name.lower().startswith(brand.lower()):
            return brand
    return name.split()[0]  # fallback

headers = {"User-Agent": "Mozilla/5.0"}

# üîÑ Scrape from page 2 to 30
for i in range(2, 31):
    url = f"https://www.flipkart.com/search?q=mobiles+under+30k&page={i}"
    r = requests.get(url, headers=headers)
    soup = BeautifulSoup(r.text, "lxml")
    box = soup.find("div", class_="DOjaWF gdgoEp")

    if box is None:
        print(f"[!] Product container not found on page {i}")
        continue

    names = box.find_all("div", class_="KzDlHZ")
    prices = box.find_all("div", class_="Nx9bqj _4b5DiR")
    descriptions = box.find_all("ul", class_="G4BRas")
    reviews = box.find_all("div", class_="XQDdHH")

    min_length = min(len(names), len(prices), len(descriptions), len(reviews))

    for j in range(min_length):
        name = names[j].text.strip()
        price = prices[j].text.strip()
        desc = descriptions[j].text.strip()
        review = reviews[j].text.strip()

        # Extract RAM, ROM, Battery using regex
        ram_match = re.search(r'(\d{1,2})\s?GB\s?(RAM|Memory)', desc, re.IGNORECASE)
        rom_match = re.search(r'(\d{2,4})\s?GB\s?(ROM|Storage)', desc, re.IGNORECASE)
        battery_match = re.search(r'(\d{4,5})\s?mAh', desc, re.IGNORECASE)

        RAM.append(ram_match.group(1) + " GB" if ram_match else None)
        ROM.append(rom_match.group(1) + " GB" if rom_match else None)
        Battery.append(battery_match.group(1) + " mAh" if battery_match else None)

        # Clean description
        cleaned_desc = re.sub(r'(\d+\s?GB\s?(RAM|Memory))', '', desc, flags=re.IGNORECASE)
        cleaned_desc = re.sub(r'(\d+\s?GB\s?(ROM|Storage))', '', cleaned_desc, flags=re.IGNORECASE)
        cleaned_desc = re.sub(r'(\d{4,5}\s?mAh.*?)(Battery)?', '', cleaned_desc, flags=re.IGNORECASE)
        cleaned_desc = re.sub(r'\s{2,}', ' ', cleaned_desc).strip()

        # Append all data
        Product_Name.append(name)
        Prices.append(price)
        Description.append(cleaned_desc)
        Reviews.append(review)
        Brands.append(extract_brand(name))

# ‚úÖ Create DataFrame
df = pd.DataFrame({
    "Brand": Brands,
    "Product Name": Product_Name,
    "Prices": Prices,
    "RAM": RAM,
    "ROM": ROM,
    "Battery": Battery,
    "Description": Description,
    "Reviews": Reviews
})

# üö´ Remove unwanted brands
df = df[~df['Product Name'].str.contains(r'everyday|duracell', flags=re.IGNORECASE, regex=True)]

# üîÅ Remove duplicate product names
df = df.drop_duplicates(subset=['Product Name'])

# ‚úÖ Final Check
print(f"\nTotal Products in Final Data: {len(df)}")

# üíæ Save CSV
df.to_csv(r"C:/Users/gadit/OneDrive/Desktop/FK_under_30k_final.csv", index=False)
print("[‚úî] Cleaned CSV with Brand column saved successfully.")
